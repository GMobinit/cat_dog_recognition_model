{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GMobinit/cat_dog_recognition_model/blob/main/cat_dog_recognition_vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip"
      ],
      "metadata": {
        "id": "k6MIQZ7ovEj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "Vcfps0R1xyKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zipfile.ZipFile('kagglecatsanddogs_5340.zip', 'r').extractall('dataset')"
      ],
      "metadata": {
        "id": "otgZcndVyV5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path('dataset/PetImages').with_suffix('')"
      ],
      "metadata": {
        "id": "uo-2Y69ty6D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_image_count = len(list(data_dir.glob('Cat/*.jpg')))\n",
        "dog_image_count = len(list(data_dir.glob('Dog/*.jpg')))\n",
        "print(f\"cat image count: {cat_image_count}, dog image count: {dog_image_count}, all images: {cat_image_count+dog_image_count}\")"
      ],
      "metadata": {
        "id": "KCmYfhjv1wdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import PIL"
      ],
      "metadata": {
        "id": "txJdA2sF2gTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PIL.Image.open(str(list(data_dir.glob('Cat/910.jpg'))[0]))"
      ],
      "metadata": {
        "id": "sATsJPtQp-5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_ds  = tf.data.Dataset.list_files(str(data_dir/'*/*.jpg'), shuffle=False)\n",
        "list_ds = list_ds.shuffle(cat_image_count+dog_image_count, reshuffle_each_iteration=False)\n",
        "print(len(list_ds))"
      ],
      "metadata": {
        "id": "348De253q2GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_add in list_ds.take(5):\n",
        "  print(file_add)"
      ],
      "metadata": {
        "id": "7PzZVLnsrjLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "for item in data_dir.glob('*'):\n",
        "  labels.append(item.name)\n",
        "\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "EMzJO8ERsl1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train validation split\n",
        "validation_percentage = 0.2\n",
        "validation_size = int((cat_image_count+dog_image_count)*validation_percentage)\n",
        "print(validation_size)\n",
        "print(len(list_ds))\n",
        "validation_ds = list_ds.take(validation_size)\n",
        "train_ds = list_ds.skip(validation_size)\n",
        "\n",
        "print(f'validation size {len(validation_ds)}, train size {len(train_ds)}')"
      ],
      "metadata": {
        "id": "r4sWGw7LtLiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def get_label(file_path):\n",
        "  separated_path = tf.strings.split(file_path, os.path.sep)\n",
        "  label = separated_path[-2]\n",
        "  one_hotted_label = (label == labels)\n",
        "  return tf.argmax(one_hotted_label)"
      ],
      "metadata": {
        "id": "RBbuPTsXuBna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_label('dataset/kagglecatsanddogs_3367a/PetImages/Cat/7411.jpg')"
      ],
      "metadata": {
        "id": "CbQYQc4pf0Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "7Jld2idhf66n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_img(encoded_img):\n",
        "  img = tf.io.decode_jpeg(encoded_img, channels=3)\n",
        "  img = tf.image.resize(img, [img_height, img_width], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return img"
      ],
      "metadata": {
        "id": "u9DyZf_vhcXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_path(img_path):\n",
        "  label = get_label(img_path)\n",
        "  img = tf.io.read_file(img_path)\n",
        "  if tf.equal(tf.strings.length(img), 0):\n",
        "    print(\"warning: empty file at \", img)\n",
        "  try:\n",
        "    img = decode_img(img)\n",
        "  except Exception as e:\n",
        "    print(f\"wrong image format {img_path}\")\n",
        "  print(img)\n",
        "  img = tf.cast(img, tf.float32)\n",
        "  # img = ((img/255))\n",
        "  return img, label"
      ],
      "metadata": {
        "id": "L9rwy4RmiDjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def is_valid_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    # Check if the file can be decoded as a JPEG image\n",
        "    is_jpeg = tf.image.is_jpeg(img)\n",
        "    return is_jpeg"
      ],
      "metadata": {
        "id": "AP8002kbtDGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "filtered_train_ds = train_ds.filter(is_valid_image)\n",
        "filtered_validation_ds = validation_ds.filter(is_valid_image)\n",
        "\n",
        "# Count the elements in the filtered datasets\n",
        "train_count = 0\n",
        "for _ in filtered_train_ds:\n",
        "  train_count += 1\n",
        "\n",
        "validation_count = 0\n",
        "for _ in filtered_validation_ds:\n",
        "  validation_count += 1\n",
        "\n",
        "\n",
        "mapped_train_ds = filtered_train_ds.map(map_func= process_path,num_parallel_calls=AUTOTUNE)\n",
        "mapped_validation_ds = filtered_validation_ds.map(map_func=process_path, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# Add checks to see the size of the datasets after filtering\n",
        "print(f\"Size of filtered_train_ds after filtering: {train_count}\")\n",
        "print(f\"Size of filtered_validation_ds after filtering: {validation_count}\")\n",
        "print(f\"Size of all filtered data: {validation_count+train_count}\")\n",
        "print(f\"Size of mapped_train_ds after filtering: {tf.data.experimental.cardinality(mapped_train_ds).numpy()}\")\n",
        "print(f\"Size of mapped_validation_ds after filtering: {tf.data.experimental.cardinality(mapped_validation_ds).numpy()}\")"
      ],
      "metadata": {
        "id": "dwjdxC-MkFlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for item in mapped_train_ds.take(5):\n",
        "#   print(\"Image shape: \", item)"
      ],
      "metadata": {
        "id": "dRhU8w9fljkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_for_performance(ds: tf.data.Dataset):\n",
        "  # ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=500)\n",
        "  ds = ds.batch(batch_size, drop_remainder=True)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "metadata": {
        "id": "sbwkt8oEl4so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_performance_train_ds = configure_for_performance(mapped_train_ds)\n",
        "high_performance_validation_ds = configure_for_performance(mapped_validation_ds)\n",
        "\n",
        "validation_count = 0\n",
        "for _ in high_performance_validation_ds:\n",
        "  validation_count += 1\n",
        "print(f\"Size of high_performance_validation_ds: {validation_count}\")"
      ],
      "metadata": {
        "id": "K1P2wJwoo-qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a,b in high_performance_train_ds.take(1):\n",
        "  print(a.shape)\n",
        "  print(b.numpy())"
      ],
      "metadata": {
        "id": "tqDDBClZpMXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for image_batch, label_batch in high_performance_train_ds.take(1):\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3,3,i+1)\n",
        "    plt.imshow(image_batch[i].numpy().astype(\"uint32\"))\n",
        "    label = label_batch[i]\n",
        "    plt.title(labels[label])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "TIuDmi-WpUbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(180,180,3))"
      ],
      "metadata": {
        "id": "HXi856Saq49L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "j5WhzoJqtyYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "dense_layer = tf.keras.layers.Dense(100, activation='relu')\n",
        "dropout_layer = tf.keras.layers.Dropout(0.5)\n",
        "prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')"
      ],
      "metadata": {
        "id": "zfB0fZJUt6wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  base_model,\n",
        "  flatten_layer,\n",
        "  dense_layer,\n",
        "  dropout_layer,\n",
        "  prediction_layer\n",
        "])"
      ],
      "metadata": {
        "id": "MuiqWA1wuovp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss = tf.keras.losses.BinaryCrossentropy, metrics=['acc'])"
      ],
      "metadata": {
        "id": "BMdwGeTtu5th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "nH01Mq__vsY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(high_performance_train_ds, epochs=30, validation_data=high_performance_validation_ds)"
      ],
      "metadata": {
        "id": "e_Wx_dI7wAwJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}